2024-06-20 18:10:49,770 - root - INFO - driver - main - creating spark session
2024-06-20 18:10:49,771 - Create_spark - INFO - create_spark - get_spark - started creating spark object
2024-06-20 18:10:57,771 - Create_spark - INFO - create_spark - get_spark - created spark session
2024-06-20 18:10:57,771 - root - INFO - driver - main - spark session has been created successfully
2024-06-20 18:10:57,771 - root - INFO - driver - main - trying to read source dataframe for cutomers
2024-06-20 18:10:57,771 - root - INFO - driver - main - trying to get schema for customer
2024-06-20 18:10:57,772 - Utils - INFO - utils - get_schema_from_json_file - trying to get schema for C:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\customers_schema\schema_customers.json
2024-06-20 18:11:00,235 - Utils - INFO - utils - get_schema_from_json_file - schema has been created forC:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\customers_schema\schema_customers.json
2024-06-20 18:11:00,236 - Utils - INFO - utils - get_source_dataframe - trying to create dataframe forC:\Users\saura\Desktop\pyspark_check\landing_zone\customers\customers.json
2024-06-20 18:11:00,275 - Utils - INFO - utils - get_source_dataframe - dataframe has been created for C:\Users\saura\Desktop\pyspark_check\landing_zone\customers\customers.json
2024-06-20 18:11:00,275 - Utils - INFO - utils - get_source_dataframe - dropping null records if any for C:\Users\saura\Desktop\pyspark_check\landing_zone\customers\customers.json
2024-06-20 18:11:00,293 - Utils - INFO - utils - get_source_dataframe - dropping null records if any has been completed for C:\Users\saura\Desktop\pyspark_check\landing_zone\customers\customers.json
2024-06-20 18:11:00,293 - Utils - INFO - utils - get_schema_from_json_file - trying to get schema for C:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\promotions_schema\schema_promotions.json
2024-06-20 18:11:00,372 - Utils - INFO - utils - get_schema_from_json_file - schema has been created forC:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\promotions_schema\schema_promotions.json
2024-06-20 18:11:00,372 - Utils - INFO - utils - get_source_dataframe - trying to create dataframe forC:\Users\saura\Desktop\pyspark_check\landing_zone\promotions\
2024-06-20 18:11:00,398 - Utils - INFO - utils - get_source_dataframe - dataframe has been created for C:\Users\saura\Desktop\pyspark_check\landing_zone\promotions\
2024-06-20 18:11:00,398 - Utils - INFO - utils - get_source_dataframe - dropping null records if any for C:\Users\saura\Desktop\pyspark_check\landing_zone\promotions\
2024-06-20 18:11:00,405 - Utils - INFO - utils - get_source_dataframe - dropping null records if any has been completed for C:\Users\saura\Desktop\pyspark_check\landing_zone\promotions\
2024-06-20 18:11:00,452 - Utils - INFO - utils - get_schema_from_json_file - trying to get schema for C:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\products_schema\schema_products.json
2024-06-20 18:11:00,533 - Utils - INFO - utils - get_schema_from_json_file - schema has been created forC:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\products_schema\schema_products.json
2024-06-20 18:11:00,533 - Utils - INFO - utils - get_source_dataframe - trying to create dataframe forC:\Users\saura\Desktop\pyspark_check\landing_zone\products\
2024-06-20 18:11:00,579 - Utils - INFO - utils - get_source_dataframe - dataframe has been created for C:\Users\saura\Desktop\pyspark_check\landing_zone\products\
2024-06-20 18:11:00,579 - Utils - INFO - utils - get_source_dataframe - dropping null records if any for C:\Users\saura\Desktop\pyspark_check\landing_zone\products\
2024-06-20 18:11:00,589 - Utils - INFO - utils - get_source_dataframe - dropping null records if any has been completed for C:\Users\saura\Desktop\pyspark_check\landing_zone\products\
2024-06-20 18:11:00,589 - Utils - INFO - utils - get_schema_from_json_file - trying to get schema for C:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\transactions_schema\schema_transactions.json
2024-06-20 18:11:00,667 - Utils - INFO - utils - get_schema_from_json_file - schema has been created forC:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\transactions_schema\schema_transactions.json
2024-06-20 18:11:00,667 - Utils - INFO - utils - get_source_dataframe - trying to create dataframe forC:\Users\saura\Desktop\pyspark_check\landing_zone\transactions\transactions.json
2024-06-20 18:11:00,684 - Utils - INFO - utils - get_source_dataframe - dataframe has been created for C:\Users\saura\Desktop\pyspark_check\landing_zone\transactions\transactions.json
2024-06-20 18:11:00,684 - Utils - INFO - utils - get_source_dataframe - dropping null records if any for C:\Users\saura\Desktop\pyspark_check\landing_zone\transactions\transactions.json
2024-06-20 18:11:00,693 - Utils - INFO - utils - get_source_dataframe - dropping null records if any has been completed for C:\Users\saura\Desktop\pyspark_check\landing_zone\transactions\transactions.json
2024-06-20 18:11:00,715 - Utils - INFO - utils - get_schema_from_json_file - trying to get schema for C:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\return_products_schema\schema_return_products.json
2024-06-20 18:11:00,778 - Utils - INFO - utils - get_schema_from_json_file - schema has been created forC:\Users\saura\Desktop\pyspark_check\properties\source_file_schema\return_products_schema\schema_return_products.json
2024-06-20 18:11:00,778 - Utils - INFO - utils - get_source_dataframe - trying to create dataframe forC:\Users\saura\Desktop\pyspark_check\landing_zone\return_products\return_products.json
2024-06-20 18:11:00,794 - Utils - INFO - utils - get_source_dataframe - dataframe has been created for C:\Users\saura\Desktop\pyspark_check\landing_zone\return_products\return_products.json
2024-06-20 18:11:00,794 - Utils - INFO - utils - get_source_dataframe - dropping null records if any for C:\Users\saura\Desktop\pyspark_check\landing_zone\return_products\return_products.json
2024-06-20 18:11:00,800 - Utils - INFO - utils - get_source_dataframe - dropping null records if any has been completed for C:\Users\saura\Desktop\pyspark_check\landing_zone\return_products\return_products.json
2024-06-20 18:11:02,371 - Data_transformations - INFO - data_transformations - get_common_product_set - Started calculating common sets of products that appear together
2024-06-20 18:11:02,487 - root - INFO - driver - main - printing product_list_df dataframe
2024-06-20 18:11:03,275 - Data_transformations - INFO - data_transformations - get_final_transactions - Started calculating the final transactions dataframe
2024-06-20 18:11:03,545 - root - INFO - driver - main - printing transactions_customers_products_promos_prices_returns_df dataframe
2024-06-20 18:11:04,096 - root - INFO - driver - main - showing sales_agg_by_transactions_df
2024-06-20 18:11:04,798 - root - INFO - driver - main - showing tax_agg_by_transactions_df
2024-06-20 18:11:05,267 - root - INFO - driver - main - showing sales_tax_agg_by_day
2024-06-20 18:11:05,747 - root - INFO - driver - main - showing amount_by_customer_df
2024-06-20 18:11:06,181 - root - INFO - driver - main - showing sales_tax_by_products_df
2024-06-20 18:11:06,520 - root - INFO - driver - main - showing sales_by_tax_brackets
2024-06-20 18:11:06,919 - root - INFO - driver - main - showing sales_by_promotions_membership_level
2024-06-20 18:11:07,241 - Data_transformations - INFO - data_transformations - get_segments_on_expenditure_and_habits - the segmenting_on_expenditure_df has failed ERROR : 'DataFrame' object has no attribute 'desc'
2024-06-20 18:11:07,241 - root - INFO - driver - main - showing segmenting_on_expenditure_df
